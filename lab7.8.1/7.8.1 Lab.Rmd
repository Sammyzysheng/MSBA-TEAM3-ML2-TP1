---
title: "Team 3 Presentation"
author: "Cody Clark"
date: "1/29/2020"
output: html_document
---

```{R}
library(ISLR)
attach(Wage)
fit=lm(wage∼poly(age ,4) ,data=Wage)
coef(summary (fit))
```



```{R}
fit2=lm(wage∼poly(age ,4,raw=T),data=Wage)
coef(summary(fit2))
```



```{R}
fit2a=lm(wage∼age+I(age^2)+I(age^3)+I(age^4),data=Wage)
coef(fit2a)
```

```{R}
fit2b=lm(wage∼cbind(age ,age^2,age^3, age ^4),data=Wage)
coef(fit2b)
```

```{R}
agelims=range(age)
age.grid=seq(from=agelims[1],to=agelims[2])
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
```

``` {R}
par(mfrow=c(1,1),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=T)
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
```

```{R}
preds2=predict(fit2,newdata=list(age=age.grid),se=TRUE)
max(abs(preds$fit-preds2$fit))
```

##Choosing a "Best" Model

First, we must decide what degree polynomial to use. Hypothesis testing is one way to do this. We use the anova() function to compare the five models and test for the following hypotheses:

Null: The initial, simple model (M1) is sufficient to explain the model Alternative: A more complex model (M2) is required

Note: M1’s features must be a subset of M2’s (nested models).

```{R}
fit.1=lm(wage~age,data=Wage)
fit.2=lm(wage~poly(age,2),data=Wage)
fit.3=lm(wage~poly(age,3),data=Wage)
fit.4=lm(wage~poly(age,4),data=Wage)
fit.5=lm(wage~poly(age,5),data=Wage)
anova(fit.1,fit.2,fit.3,fit.4,fit.5)
```

Comparing the p-values shows us that either a degree 3 or 4 polynomial appears to offer the best fit for the model.
The p-values can be obtained more easily as follows:

```{R}
coef(summary(fit.5))
```

The p-values are the same, and the t-statistics are the square roots of the F-statistics obtained via the anova() function.

```{R}
(-11.983)^2
```

```{R}
fit.1=lm(wage~education+age,data=Wage)
fit.2=lm(wage~education+poly(age,2),data=Wage)
fit.3=lm(wage~education+poly(age,3),data=Wage)
anova(fit.1,fit.2,fit.3)
```

# Polynomial Logistic Regression

In this instance the topic of interest is whether or not the polynomials of age can predict whether an individual earns more than $250,000 per year.

We fit a logistic regression model to a binary response variable utilzing the 'Wrapper (I)' function below. This expression (I(wage>250)) evaluates to a logical variable containing TRUEs and FALSEs, which glm() coerces into binary by setting the TRUEs to 1 and FALSEs to 0. 

```{R}
fit=glm(I(wage>250)~poly(age,4),data=Wage,family=binomial)
summary(fit)
```

Utilize the predict function to make predictions of the polynomial logistic regression model. The default prediction type for a glm() model is type="link", which means we calculate predictions for the logit (log-odds) rather than probabilities.

```{R}
preds=predict(fit,newdata=list(age=age.grid),se=T)
```

Calculating confience intervals and standard error bands. Since the computations are logit we will need to apply inverse logit mapping.

```{R}
pfit = exp(preds$fit) / (1+exp(preds$fit))
se.bands.logit = cbind(lower=preds$fit-2*preds$se.fit,upper=preds$fit+2*preds$se.fit)
se.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))
tail(se.bands)
```

This is an example of a type="response" prediction should be set up, however, it is yielding negative probabilities and should not be used!

```{R}
pred.p=predict(fit,newdata=list(age=age.grid),type="response",se=T)
```

Graph The Data

Below is the code and plot associated with predicted fit and standard error bands. Observed wage values greater than 250K are shown as gray marks at the top of the plot while observations of wage values less than 250K are shown as gray marks at the bottom of the plot.

```{R}
plot(age,I(wage>250),xlim=agelims,type="n",ylim=c(0,.2))
points(jitter(age), I((wage>250)/5),cex=.5,pch="|",col="darkgrey")
lines(age.grid,pfit,lwd=2, col="blue")
matlines(age.grid,se.bands,lwd=1,col="red",lty=3)
```

Jitter() function is used so age observations with the same value do not cover each other.
This plot is sometimes referred to as a rug plot.

Step Function

In this exercise we utilize the cut function to break the age variable into 4 segments and then build a linear model according to the segments.

```{R}
table(cut(age,4))
fit=lm(wage~cut(age,4),data=Wage)
coef(summary(fit))
```

The function cut() returns an ordered categorical variable; the lm() function then creates a set of dummy variables for use in the regression. The age<33.5 category is left out, so the intercept coefficient of $94,160 can be interpreted as the average salary for those under 33.5 years of age, and the other coefficients can be interpreted as the average additional salary for those in the other age groups.
